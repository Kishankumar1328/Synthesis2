# ğŸ“Š Analytics Dashboard - Quick Reference

## ğŸ¯ Architecture Summary

| Layer | Technology | File | Purpose |
|-------|-----------|------|---------|
| **Frontend** | React + Chart.js | `AnalyticsDashboard.jsx` (1,829 lines) | Interactive data visualization |
| **Backend** | Spring Boot | `DatasetController.java` | REST API endpoints |
| **Service** | Java | `DatasetService.java` | File management |
| **AI Service** | Java + Python | `AIService.java` | Python integration |
| **Database** | H2 (In-Memory) | `Dataset.java` | Metadata storage |
| **AI Engine** | Python + pandas | `stats.py` (97 lines) | Statistical analysis |

---

## ğŸ”„ Complete Data Flow

```
1. User uploads file â†’ 2. Backend saves to disk â†’ 3. H2 stores metadata
                                                           â†“
4. User clicks "Data Insights" â†’ 5. Backend queries H2 â†’ 6. Gets file path
                                                           â†“
7. Backend calls Python â†’ 8. stats.py analyzes â†’ 9. Returns JSON
                                                           â†“
10. Frontend renders charts â† 11. User sees analytics
```

---

## ğŸ“ Key Files

### Frontend
- **`frontend/src/components/AnalyticsDashboard.jsx`**
  - Lines: 1,829
  - Components: 15+ (KPICard, FeatureChart, CorrelationMatrix, etc.)
  - Features: KPIs, Charts, Insights, Correlations, Network Graphs

### Backend
- **`backend/src/.../controller/DatasetController.java`**
  - Endpoint: `GET /api/datasets/{id}/stats`
  - Returns: JSON statistics

- **`backend/src/.../service/DatasetService.java`**
  - Method: `uploadDataset(file, projectId)`
  - Stores: `fileName` (not absolute path) âœ…

- **`backend/src/.../service/AIService.java`**
  - Method: `getDatasetStats(fileName)`
  - Executes: `python stats.py --data <path>`
  - Caching: `@Cacheable("datasetStats")`

### AI Engine
- **`ai-engine/stats.py`**
  - Lines: 97
  - Supports: CSV, Excel (.xlsx, .xls)
  - Returns: JSON with rowCount, columns, correlation

---

## ğŸ—„ï¸ Database Schema

```sql
TABLE: dataset
- id (PK, BIGINT, AUTO_INCREMENT)
- name (VARCHAR, NOT NULL)
- file_path (VARCHAR) âœ… Stores: "uuid_filename.csv"
- row_count (INTEGER)
- column_count (INTEGER)
- file_size (BIGINT)
- project_id (FK, BIGINT)
- created_at (TIMESTAMP)
- updated_at (TIMESTAMP)
```

**Important**: `file_path` stores **only the filename**, not the full path!

---

## ğŸ”§ Recent Fixes

### Fix 1: Excel Support (stats.py)
```python
# Before: Only CSV
df = pd.read_csv(data_path)

# After: CSV + Excel
file_ext = data_path.lower().split('.')[-1]
if file_ext in ['xlsx', 'xls']:
    df = pd.read_excel(data_path, engine='openpyxl')
else:
    df = pd.read_csv(data_path)
```

### Fix 2: Error Handling (AnalyticsDashboard.jsx)
```javascript
// Added error state
if (stats.error) {
    return <ErrorDisplay message={stats.error} />;
}
```

### Fix 3: Path Duplication (DatasetService.java)
```java
// Before: Stored absolute path
dataset.setFilePath(filePath.toString()); // âŒ

// After: Store only filename
dataset.setFilePath(fileName); // âœ…
```

---

## ğŸ“Š JSON Response Format

```json
{
  "rowCount": 50,
  "columnCount": 7,
  "columns": [
    {
      "name": "age",
      "type": "int64",
      "nullPercentage": 0.0,
      "uniqueCount": 18,
      "stats": { "min": 26, "max": 45, "mean": 34.5, "median": 34 },
      "distribution": {
        "labels": ["26-28", "29-31", ...],
        "values": [5, 8, 12, ...]
      }
    }
  ],
  "correlation": {
    "columns": ["age", "salary", "experience"],
    "values": [[1.0, 0.85, 0.92], ...]
  }
}
```

---

## ğŸš€ API Endpoints

| Method | Endpoint | Description |
|--------|----------|-------------|
| POST | `/api/datasets/upload` | Upload CSV/Excel file |
| GET | `/api/datasets/{id}/stats` | Get statistical analysis |
| GET | `/api/datasets/project/{projectId}` | List datasets by project |
| DELETE | `/api/datasets/{id}` | Delete dataset |

---

## âš¡ Performance

### Caching
- **First request**: 2-5 seconds (Python execution)
- **Cached requests**: 10-50ms (from Spring Cache)
- **Cache key**: `fileName`
- **Cache invalidation**: Backend restart

### Frontend Optimization
- `useMemo` for metrics computation
- `useMemo` for insights generation
- `useMemo` for column filtering
- Lazy loading for charts

---

## ğŸ” Troubleshooting

### Issue: "File not found"
**Cause**: Path duplication
**Fix**: Ensure `DatasetService` stores only filename (line 113)

### Issue: "Failed to parse Excel"
**Cause**: Missing openpyxl
**Fix**: `pip install openpyxl==3.1.2`

### Issue: Data lost after restart
**Cause**: H2 in-memory database
**Fix**: Re-upload datasets or switch to MySQL

---

## ğŸ“š Documentation Files

1. **`ANALYTICS_DASHBOARD_ARCHITECTURE.md`** - Complete technical analysis (200+ lines)
2. **`ANALYTICS_ARCHITECTURE_DIAGRAMS.md`** - Visual diagrams and flows
3. **`DATA_INSIGHTS_COMPLETE.md`** - Fix summary and testing guide
4. **`PATH_FIX_COMPLETE.md`** - Path duplication fix details

---

## âœ… Status

- âœ… Excel support working
- âœ… Error handling implemented
- âœ… Path duplication fixed
- âœ… All 3 layers analyzed
- âœ… Documentation complete

**Ready for production!** ğŸš€
